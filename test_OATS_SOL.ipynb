{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n",
      "GPUs Count: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os, time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "from dataloaders.cifar10 import cifar10_dataloaders\n",
    "from dataloaders.svhn import svhn_dataloaders\n",
    "from dataloaders.stl10 import stl10_dataloaders\n",
    "from utils.utils import *\n",
    "from utils.context import ctx_noparamgrad_and_eval\n",
    "from utils.sample_lambda import element_wise_sample_lambda\n",
    "from attacks.pgd import PGD\n",
    "import multiprocessing as mp\n",
    "mp.set_start_method('spawn', force=True) ### to avoid Caffe Warnings\n",
    "\n",
    "################################################ Importing Models and Width Multiplier List\n",
    "from models.slimmable_ops import width_mult_list\n",
    "from models.cifar10.resnet_slimmable_OAT import SlimmableResNet34OAT, SlimmableResNet34OAT_SOL\n",
    "from models.svhn.wide_resnet_slimmable_OAT import SlimmableWideResNet_16_8_OAT, SlimmableWideResNet_16_8_OAT_SOL\n",
    "from models.stl10.wide_resnet_slimmable_OAT import SlimmableWideResNet_40_2_OAT, SlimmableWideResNet_40_2_OAT_SOL\n",
    "\n",
    "# Setting Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('GPU') if str(device) == \"cuda:0\" else print('GPU not Detected - CPU Selected')\n",
    "print(f\"GPUs Count: {torch.cuda.device_count()}\") # Show how many GPUs are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=3):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.set_default_dtype(torch.float32)\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "./OATS_results/cifar10/SlimmableResNet34OAT/PGD_7_Epochs120_BatchSize128_LR0.1\n"
     ]
    }
   ],
   "source": [
    "#################### Setting Hyperparameters\n",
    "class Arguments:\n",
    "    gpu = '0'\n",
    "    cpus = 4\n",
    "    dataset = 'cifar10'\n",
    "    batch_size, dim = 128, 128\n",
    "    epochs = 120\n",
    "    lr = 0.1\n",
    "    momentum = 0.9\n",
    "    wd = 5e-4\n",
    "    eps = 8     # eps/255 (L-inf norm bound)\n",
    "    steps = 7   # PGD Steps\n",
    "    distribution = 'disc'\n",
    "    probs = -1\n",
    "    lambda_choices = [0.0, 0.1, 0.2, 0.3, 0.4, 1.0]\n",
    "    use2BN = True    ### Use Dual Batch Norm\n",
    "    efficient = True\n",
    "\n",
    "args = Arguments()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "############### DATA LOADERS:\n",
    "if args.dataset == 'cifar10':\n",
    "    train_loader, val_loader, test_loader = cifar10_dataloaders(train_batch_size=args.batch_size, num_workers=args.cpus)\n",
    "elif args.dataset == 'svhn':\n",
    "    train_loader, val_loader, test_loader = svhn_dataloaders(train_batch_size=args.batch_size, num_workers=args.cpus)\n",
    "elif args.dataset == 'stl10':\n",
    "    train_loader, val_loader = stl10_dataloaders(train_batch_size=args.batch_size, num_workers=args.cpus)\n",
    "\n",
    "############### MODEL SELECTION:\n",
    "FiLM_in_channels = args.dim\n",
    "\n",
    "if args.dataset == 'cifar10':\n",
    "    model_fn = SlimmableResNet34OAT\n",
    "    model = model_fn(use2BN=args.use2BN, FiLM_in_channels=FiLM_in_channels).cuda()\n",
    "elif args.dataset == 'svhn':\n",
    "    model_fn = SlimmableWideResNet_16_8_OAT\n",
    "    model = model_fn(depth=16, num_classes=10, widen_factor=8, dropRate=0.0, use2BN=True, FiLM_in_channels=FiLM_in_channels).cuda()\n",
    "elif args.dataset == 'stl10':\n",
    "    model_fn = SlimmableWideResNet_40_2_OAT\n",
    "    model = model_fn(depth=40, num_classes=10, widen_factor=2, dropRate=0.0, use2BN=True, FiLM_in_channels=FiLM_in_channels).cuda()\n",
    "\n",
    "############### LAMBDA Encoding Matrix:\n",
    "rand_mat = np.random.randn(args.dim, args.dim)\n",
    "rand_otho_mat, _ = np.linalg.qr(rand_mat)\n",
    "encoding_mat = rand_otho_mat\n",
    "\n",
    "############### ATTACKER\n",
    "attacker = PGD(eps=args.eps/255, steps=args.steps, use_FiLM=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of Sub-Nets: {len(width_mult_list)}\")    # Note: width_mult_list should be compatible with the model to be evaluated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load Trained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### For loading Best MODELs\n",
    "model_path = \"./OATS_results/\"   ##############  Provide Correct Model Path\n",
    "model_name = \"Best_Model.pth\"    ##############  Use Correct Model Name\n",
    "\n",
    "model_path = model_path + model_name\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    ################################## TESTING\n",
    "    model.eval()\n",
    "    requires_grad_(model, False)\n",
    "    test_lambdas = [0.0, 0.1, 0.2, 0.3, 0.4, 1.0]\n",
    "    \n",
    "    test_accs, test_accs_adv = {}, {}\n",
    "    for test_lambda in test_lambdas:\n",
    "        test_accs[test_lambda], test_accs_adv[test_lambda] = AverageMeter(), AverageMeter()\n",
    "\n",
    "    for i, (imgs, labels) in enumerate(test_loader):\n",
    "        imgs, labels = imgs.cuda(), labels.cuda()\n",
    "        for j, test_lambda in enumerate(test_lambdas):\n",
    "            # sample _lambda:\n",
    "            if args.distribution == 'disc' and encoding_mat is not None:\n",
    "                _lambda = np.expand_dims( np.repeat(j, labels.size()[0]), axis=1 ).astype(np.uint8)\n",
    "                _lambda = encoding_mat[_lambda,:] \n",
    "            else:\n",
    "                _lambda = np.expand_dims( np.repeat(test_lambda, labels.size()[0]), axis=1 )\n",
    "            _lambda = torch.from_numpy(_lambda).float().cuda()\n",
    "            if args.use2BN:\n",
    "                idx2BN = int(labels.size()[0]) if test_lambda==0 else 0\n",
    "            else:\n",
    "                idx2BN = None\n",
    "            ##### TA:\n",
    "            logits = model(imgs, _lambda, idx2BN)\n",
    "            test_accs[test_lambda].append((logits.argmax(1) == labels).float().mean().item())\n",
    "            \n",
    "            ##### ATA:\n",
    "            with ctx_noparamgrad_and_eval(model):\n",
    "                imgs_adv = attacker.attack(model, imgs, labels=labels, _lambda=_lambda, idx2BN=idx2BN)  # generate adversarial images:\n",
    "            logits_adv = model(imgs_adv.detach(), _lambda, idx2BN)\n",
    "            test_accs_adv[test_lambda].append((logits_adv.argmax(1) == labels).float().mean().item())\n",
    "\n",
    "    lambdas, accuracies, robustness = [], [], []\n",
    "    for test_lambda in test_lambdas:\n",
    "        lambdas.append(test_lambda)\n",
    "        accuracies.append(test_accs[test_lambda].avg)\n",
    "        robustness.append(test_accs_adv[test_lambda].avg)\n",
    "    print(accuracies)\n",
    "    print(robustness)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_net_width = 0\n",
    "test_accuracies = []\n",
    "\n",
    "for i in range(len(width_mult_list)):\n",
    "    sub_net_width += 1/len(width_mult_list)\n",
    "    i+=1\n",
    "    print(f\"SubNet-ID: {i}\")\n",
    "    model.apply(lambda m: setattr(m, 'width_mult', sub_net_width))\n",
    "    test_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ofa_adv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
